{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "True\n",
      "4\n",
      "Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import torch.multiprocessing as mp\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enP5p1s0f0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\r\n",
      "        inet 169.254.10.231  netmask 255.255.255.0  broadcast 169.254.10.255\r\n",
      "        inet6 fe80::a94:efff:fe80:317  prefixlen 64  scopeid 0x20<link>\r\n",
      "        ether 08:94:ef:80:03:17  txqueuelen 1000  (Ethernet)\r\n",
      "        RX packets 234867969  bytes 20748221612 (19.3 GiB)\r\n",
      "        RX errors 0  dropped 0  overruns 0  frame 0\r\n",
      "        TX packets 208396066  bytes 42416777951 (39.5 GiB)\r\n",
      "        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\r\n",
      "        device interrupt 80  \r\n",
      "\r\n",
      "enP5p1s0f1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\r\n",
      "        inet 192.168.20.12  netmask 255.255.255.0  broadcast 192.168.20.255\r\n",
      "        inet6 fe80::a94:efff:fe80:318  prefixlen 64  scopeid 0x20<link>\r\n",
      "        ether 08:94:ef:80:03:18  txqueuelen 1000  (Ethernet)\r\n",
      "        RX packets 165965522  bytes 16537219704 (15.4 GiB)\r\n",
      "        RX errors 0  dropped 173  overruns 0  frame 0\r\n",
      "        TX packets 234344805  bytes 184344974912 (171.6 GiB)\r\n",
      "        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\r\n",
      "        device interrupt 81  \r\n",
      "\r\n",
      "ib1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 2044\r\n",
      "        inet 192.168.100.12  netmask 255.255.255.0  broadcast 192.168.100.255\r\n",
      "        inet6 fe80::9a03:9b03:89:a4b  prefixlen 64  scopeid 0x20<link>\r\n",
      "Infiniband hardware address can be incorrect! Please read BUGS section in ifconfig(8).\r\n",
      "        infiniband 20:00:08:86:FE:80:00:00:00:00:00:00:00:00:00:00:00:00:00:00  txqueuelen 256  (InfiniBand)\r\n",
      "        RX packets 553652694  bytes 343469574660 (319.8 GiB)\r\n",
      "        RX errors 0  dropped 0  overruns 0  frame 0\r\n",
      "        TX packets 523446086  bytes 141143315843 (131.4 GiB)\r\n",
      "        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\r\n",
      "\r\n",
      "lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\r\n",
      "        inet 127.0.0.1  netmask 255.0.0.0\r\n",
      "        inet6 ::1  prefixlen 128  scopeid 0x10<host>\r\n",
      "        loop  txqueuelen 1000  (Local Loopback)\r\n",
      "        RX packets 2216454  bytes 2195126291 (2.0 GiB)\r\n",
      "        RX errors 0  dropped 0  overruns 0  frame 0\r\n",
      "        TX packets 2216454  bytes 2195126291 (2.0 GiB)\r\n",
      "        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!ifconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a single gpu on a single node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gpu, epochs):\n",
    "    torch.manual_seed(0)\n",
    "    model = ConvNet()\n",
    "    torch.cuda.set_device(gpu)\n",
    "    model.cuda(gpu)\n",
    "    batch_size = 100\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n",
    "    # Data loading code\n",
    "    train_dataset = torchvision.datasets.MNIST(root='/home/kexu6/DATA',\n",
    "                                               train=True,\n",
    "                                               transform=transforms.ToTensor(),\n",
    "                                               download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=0,\n",
    "                                               pin_memory=True)\n",
    "\n",
    "    start = datetime.now()\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            labels = labels.cuda(non_blocking=True)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 100 == 0 and gpu == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                    epoch + 1, \n",
    "                    epochs, \n",
    "                    i + 1, \n",
    "                    total_step,\n",
    "                    loss.item())\n",
    "                   )\n",
    "    if gpu == 0:\n",
    "        print(\"Training complete in: \" + str(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/600], Loss: 2.1626\n",
      "Epoch [1/10], Step [200/600], Loss: 1.9929\n",
      "Epoch [1/10], Step [300/600], Loss: 1.9224\n",
      "Epoch [1/10], Step [400/600], Loss: 1.7479\n",
      "Epoch [1/10], Step [500/600], Loss: 1.6264\n",
      "Epoch [1/10], Step [600/600], Loss: 1.5411\n",
      "Epoch [2/10], Step [100/600], Loss: 1.4387\n",
      "Epoch [2/10], Step [200/600], Loss: 1.3242\n",
      "Epoch [2/10], Step [300/600], Loss: 1.2894\n",
      "Epoch [2/10], Step [400/600], Loss: 1.1754\n",
      "Epoch [2/10], Step [500/600], Loss: 1.1271\n",
      "Epoch [2/10], Step [600/600], Loss: 1.1246\n",
      "Epoch [3/10], Step [100/600], Loss: 1.1838\n",
      "Epoch [3/10], Step [200/600], Loss: 1.0215\n",
      "Epoch [3/10], Step [300/600], Loss: 1.0146\n",
      "Epoch [3/10], Step [400/600], Loss: 0.9684\n",
      "Epoch [3/10], Step [500/600], Loss: 0.9130\n",
      "Epoch [3/10], Step [600/600], Loss: 0.9182\n",
      "Epoch [4/10], Step [100/600], Loss: 0.9589\n",
      "Epoch [4/10], Step [200/600], Loss: 0.8122\n",
      "Epoch [4/10], Step [300/600], Loss: 0.8425\n",
      "Epoch [4/10], Step [400/600], Loss: 0.8240\n",
      "Epoch [4/10], Step [500/600], Loss: 0.7570\n",
      "Epoch [4/10], Step [600/600], Loss: 0.7503\n",
      "Epoch [5/10], Step [100/600], Loss: 0.7066\n",
      "Epoch [5/10], Step [200/600], Loss: 0.7178\n",
      "Epoch [5/10], Step [300/600], Loss: 0.7116\n",
      "Epoch [5/10], Step [400/600], Loss: 0.6883\n",
      "Epoch [5/10], Step [500/600], Loss: 0.6398\n",
      "Epoch [5/10], Step [600/600], Loss: 0.6364\n",
      "Epoch [6/10], Step [100/600], Loss: 0.7017\n",
      "Epoch [6/10], Step [200/600], Loss: 0.6079\n",
      "Epoch [6/10], Step [300/600], Loss: 0.6091\n",
      "Epoch [6/10], Step [400/600], Loss: 0.5775\n",
      "Epoch [6/10], Step [500/600], Loss: 0.5227\n",
      "Epoch [6/10], Step [600/600], Loss: 0.5825\n",
      "Epoch [7/10], Step [100/600], Loss: 0.5179\n",
      "Epoch [7/10], Step [200/600], Loss: 0.6193\n",
      "Epoch [7/10], Step [300/600], Loss: 0.4717\n",
      "Epoch [7/10], Step [400/600], Loss: 0.5196\n",
      "Epoch [7/10], Step [500/600], Loss: 0.4860\n",
      "Epoch [7/10], Step [600/600], Loss: 0.5661\n",
      "Epoch [8/10], Step [100/600], Loss: 0.4135\n",
      "Epoch [8/10], Step [200/600], Loss: 0.5007\n",
      "Epoch [8/10], Step [300/600], Loss: 0.4772\n",
      "Epoch [8/10], Step [400/600], Loss: 0.4831\n",
      "Epoch [8/10], Step [500/600], Loss: 0.5875\n",
      "Epoch [8/10], Step [600/600], Loss: 0.5003\n",
      "Epoch [9/10], Step [100/600], Loss: 0.5162\n",
      "Epoch [9/10], Step [200/600], Loss: 0.3712\n",
      "Epoch [9/10], Step [300/600], Loss: 0.3523\n",
      "Epoch [9/10], Step [400/600], Loss: 0.4919\n",
      "Epoch [9/10], Step [500/600], Loss: 0.3316\n",
      "Epoch [9/10], Step [600/600], Loss: 0.3720\n",
      "Epoch [10/10], Step [100/600], Loss: 0.3870\n",
      "Epoch [10/10], Step [200/600], Loss: 0.5186\n",
      "Epoch [10/10], Step [300/600], Loss: 0.5316\n",
      "Epoch [10/10], Step [400/600], Loss: 0.3468\n",
      "Epoch [10/10], Step [500/600], Loss: 0.3973\n",
      "Epoch [10/10], Step [600/600], Loss: 0.3794\n",
      "Training complete in: 0:01:31.811673\n"
     ]
    }
   ],
   "source": [
    "train(gpu=0, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Paralell\n",
    "https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html\n",
    "\n",
    "Pytorch has two ways to split models and data across multiple GPUs: `nn.DataParallel` and `nn.DistributedDataParallel`. `nn.DataParallel` is easier to use (just wrap the model and run your training script). However, because it uses one process to compute the model weights and then distribute them to each GPU during each batch, networking quickly becomes a bottle-neck and GPU utilization is often very low. Furthermore, nn.DataParallel requires that all the GPUs be on the same node and doesn’t work with Apex for mixed-precision training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gpu, epochs):\n",
    "    torch.manual_seed(0)\n",
    "    model = ConvNet()\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using \", torch.cuda.device_count(), \" GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    model.cuda(gpu)\n",
    "    batch_size = 100\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n",
    "    # Data loading code\n",
    "    train_dataset = torchvision.datasets.MNIST(root='/home/kexu6/DATA',\n",
    "                                               train=True,\n",
    "                                               transform=transforms.ToTensor(),\n",
    "                                               download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=0,\n",
    "                                               pin_memory=True)\n",
    "\n",
    "    start = datetime.now()\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            labels = labels.cuda(non_blocking=True)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 100 == 0 and gpu == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                    epoch + 1, \n",
    "                    epochs, \n",
    "                    i + 1, \n",
    "                    total_step,\n",
    "                    loss.item())\n",
    "                   )\n",
    "    if gpu == 0:\n",
    "        print(\"Training complete in: \" + str(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  4  GPUs!\n",
      "Epoch [1/10], Step [100/600], Loss: 2.1628\n",
      "Epoch [1/10], Step [200/600], Loss: 1.9898\n",
      "Epoch [1/10], Step [300/600], Loss: 1.9229\n",
      "Epoch [1/10], Step [400/600], Loss: 1.7464\n",
      "Epoch [1/10], Step [500/600], Loss: 1.6278\n",
      "Epoch [1/10], Step [600/600], Loss: 1.5438\n",
      "Epoch [2/10], Step [100/600], Loss: 1.4396\n",
      "Epoch [2/10], Step [200/600], Loss: 1.3246\n",
      "Epoch [2/10], Step [300/600], Loss: 1.2891\n",
      "Epoch [2/10], Step [400/600], Loss: 1.1769\n",
      "Epoch [2/10], Step [500/600], Loss: 1.1300\n",
      "Epoch [2/10], Step [600/600], Loss: 1.1270\n",
      "Epoch [3/10], Step [100/600], Loss: 1.1857\n",
      "Epoch [3/10], Step [200/600], Loss: 1.0241\n",
      "Epoch [3/10], Step [300/600], Loss: 1.0166\n",
      "Epoch [3/10], Step [400/600], Loss: 0.9708\n",
      "Epoch [3/10], Step [500/600], Loss: 0.9145\n",
      "Epoch [3/10], Step [600/600], Loss: 0.9214\n",
      "Epoch [4/10], Step [100/600], Loss: 0.9587\n",
      "Epoch [4/10], Step [200/600], Loss: 0.8138\n",
      "Epoch [4/10], Step [300/600], Loss: 0.8442\n",
      "Epoch [4/10], Step [400/600], Loss: 0.8242\n",
      "Epoch [4/10], Step [500/600], Loss: 0.7603\n",
      "Epoch [4/10], Step [600/600], Loss: 0.7533\n",
      "Epoch [5/10], Step [100/600], Loss: 0.7102\n",
      "Epoch [5/10], Step [200/600], Loss: 0.7201\n",
      "Epoch [5/10], Step [300/600], Loss: 0.7117\n",
      "Epoch [5/10], Step [400/600], Loss: 0.6930\n",
      "Epoch [5/10], Step [500/600], Loss: 0.6418\n",
      "Epoch [5/10], Step [600/600], Loss: 0.6389\n",
      "Epoch [6/10], Step [100/600], Loss: 0.7048\n",
      "Epoch [6/10], Step [200/600], Loss: 0.6109\n",
      "Epoch [6/10], Step [300/600], Loss: 0.6093\n",
      "Epoch [6/10], Step [400/600], Loss: 0.5791\n",
      "Epoch [6/10], Step [500/600], Loss: 0.5241\n",
      "Epoch [6/10], Step [600/600], Loss: 0.5856\n",
      "Epoch [7/10], Step [100/600], Loss: 0.5204\n",
      "Epoch [7/10], Step [200/600], Loss: 0.6253\n",
      "Epoch [7/10], Step [300/600], Loss: 0.4735\n",
      "Epoch [7/10], Step [400/600], Loss: 0.5202\n",
      "Epoch [7/10], Step [500/600], Loss: 0.4858\n",
      "Epoch [7/10], Step [600/600], Loss: 0.5673\n",
      "Epoch [8/10], Step [100/600], Loss: 0.4162\n",
      "Epoch [8/10], Step [200/600], Loss: 0.5015\n",
      "Epoch [8/10], Step [300/600], Loss: 0.4791\n",
      "Epoch [8/10], Step [400/600], Loss: 0.4862\n",
      "Epoch [8/10], Step [500/600], Loss: 0.5902\n",
      "Epoch [8/10], Step [600/600], Loss: 0.5030\n",
      "Epoch [9/10], Step [100/600], Loss: 0.5186\n",
      "Epoch [9/10], Step [200/600], Loss: 0.3714\n",
      "Epoch [9/10], Step [300/600], Loss: 0.3538\n",
      "Epoch [9/10], Step [400/600], Loss: 0.4919\n",
      "Epoch [9/10], Step [500/600], Loss: 0.3334\n",
      "Epoch [9/10], Step [600/600], Loss: 0.3760\n",
      "Epoch [10/10], Step [100/600], Loss: 0.3876\n",
      "Epoch [10/10], Step [200/600], Loss: 0.5204\n",
      "Epoch [10/10], Step [300/600], Loss: 0.5393\n",
      "Epoch [10/10], Step [400/600], Loss: 0.3495\n",
      "Epoch [10/10], Step [500/600], Loss: 0.3985\n",
      "Epoch [10/10], Step [600/600], Loss: 0.3793\n",
      "Training complete in: 0:02:18.273338\n"
     ]
    }
   ],
   "source": [
    "train(gpu=0, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Data Paralell\n",
    "https://yangkky.github.io/2019/07/08/distributed-pytorch-tutorial.html\n",
    "\n",
    "https://github.com/yangkky/distributed_tutorial/blob/master/src/mnist-distributed.py\n",
    "\n",
    "https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "\n",
    "https://medium.com/intel-student-ambassadors/distributed-training-of-deep-learning-models-with-pytorch-1123fa538848\n",
    "\n",
    "http://www.telesens.co/2019/04/04/distributed-data-parallel-training-using-pytorch-on-aws/\n",
    "\n",
    "http://seba1511.net/dist_blog/\n",
    "\n",
    "Works for both single-node(multi-GPU) and multi-node data parallel training. It is proven to be significantly faster than `torch.nn.DataParallel` for single-node multi-GPU data parallel training. `nccl` backend is currently the fastest and highly recommended backend to be used with distributed training and this applies to both single-node and multi-node distributed training.\n",
    "\n",
    "Multiprocessing with DistributedDataParallel duplicates the model on each GPU on each computer node. The GPUs can all be on the same node or spread across multiple nodes. If you have 2 computer nodes with 4 GPUs each, you have a total of 8 model replicas. Each replica is controlled by one process and handles a portion of the input data.  Every process does identical tasks, and each process communicates with all the others. During the backwards pass, gradients from each node are averaged. Only gradients are passed between the processes/GPUs so that network communication is less of a bottleneck.\n",
    "\n",
    "During training, each process loads its own minibatches from disk and passes them to its GPU. Each GPU does its own forward pass, and then the gradients are all-reduced across the GPUs. Gradients for each layer do not depend on previous layers, so the gradient all-reduce is calculated concurrently with the backwards pass to futher alleviate the networking bottleneck. At the end of the backwards pass, every node has the averaged gradients, ensuring that the model weights stay synchronized.\n",
    "\n",
    "All this requires that the multiple processes, possibly on multiple nodes, are synchronized and communicate. Pytorch does this through its `distributed.init_process_group` function. This function needs to know where to find process 0 so that all the processes can sync up and the total number of processes to expect. Each individual process also needs to know the total number of processes as well as its rank within the processes and which GPU to use. It’s common to call the total number of processes the `world size`. Finally, each process needs to know which slice of the data to work on so that the batches are non-overlapping. Pytorch provides `nn.utils.data.DistributedSampler` to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gpu, world_size, nr, gpus):\n",
    "    ############################################################\n",
    "    rank = nr * gpus + gpu  # global rank of the process                       \n",
    "    dist.init_process_group(backend='nccl', \n",
    "                            init_method='env://',                                   \n",
    "                            world_size=world_size,                              \n",
    "                            rank=rank)                                                          \n",
    "    ############################################################\n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "    model = ConvNet()\n",
    "    torch.cuda.set_device(gpu)\n",
    "    model.cuda(gpu)\n",
    "    batch_size = 100\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n",
    "    \n",
    "    ###############################################################\n",
    "    # Wrap the model\n",
    "    model = nn.parallel.DistributedDataParallel(model,\n",
    "                                                device_ids=[gpu])\n",
    "    ###############################################################\n",
    "\n",
    "    # Data loading code\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "        download=True\n",
    "    )                                               \n",
    "    ################################################################\n",
    "    # makes sure that each process gets a different slice of the training data\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset,\n",
    "                                                                    num_replicas=world_size,\n",
    "                                                                    rank=rank)\n",
    "    ################################################################\n",
    "    # Use the nn.utils.data.DistributedSampler instead of shuffling the usual way\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0,\n",
    "                                               pin_memory=True,\n",
    "                                               sampler=train_sampler)\n",
    "\n",
    "    start = datetime.now()\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            labels = labels.cuda(non_blocking=True)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 100 == 0 and gpu == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                    epoch + 1, \n",
    "                    epochs, \n",
    "                    i + 1, \n",
    "                    total_step,\n",
    "                    loss.item())\n",
    "                   )\n",
    "    if gpu == 0:\n",
    "        print(\"Training complete in: \" + str(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-829e0907b38f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;31m# total number of nodes we’re going to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpus\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;31m# total number of processes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;31m# the rank of the current node within all the nodes, and goes from 0 to args.nodes - 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MASTER_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'169.254.10.248'\u001b[0m \u001b[0;31m# what IP address to look at for process 0. It needs this so that all the processes can sync up initially\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MASTER_PORT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'8888'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "gpus = 8 # number of gpus on each node\n",
    "nodes = 4 # total number of nodes we’re going to use\n",
    "world_size = gpus * nodes # total number of processes\n",
    "nr = i # the rank of the current node within all the nodes, and goes from 0 to args.nodes - 1\n",
    "os.environ['MASTER_ADDR'] = '169.254.10.231' # what IP address to look at for process 0. It needs this so that all the processes can sync up initially             \n",
    "os.environ['MASTER_PORT'] = '8888'  \n",
    "# spawn args.gpus processes, each of which runs train(i, args), where i goes from 0 to args.gpus - 1\n",
    "mp.spawn(train, nprocs=gpus, args=(gpu, world_size, nr, gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-5f034cb220d0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-5f034cb220d0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (wmlce-v1.6.2-py3.7) [kexu6@hal12 src]$ python mnist_distributed.py -n 1 -g 4 -nr 0 --epochs 10\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "(wmlce-v1.6.2-py3.7) [kexu6@hal12 src]$ python mnist_distributed.py -n 1 -g 4 -nr 0 --epochs 10\n",
    "Epoch [1/10], Step [50/150], Loss: 2.2473\n",
    "Epoch [1/10], Step [100/150], Loss: 2.1133\n",
    "Epoch [1/10], Step [150/150], Loss: 2.0436\n",
    "Epoch [2/10], Step [50/150], Loss: 2.0311\n",
    "Epoch [2/10], Step [100/150], Loss: 1.9043\n",
    "Epoch [2/10], Step [150/150], Loss: 1.8384\n",
    "Epoch [3/10], Step [50/150], Loss: 1.8513\n",
    "Epoch [3/10], Step [100/150], Loss: 1.7253\n",
    "Epoch [3/10], Step [150/150], Loss: 1.6633\n",
    "Epoch [4/10], Step [50/150], Loss: 1.6923\n",
    "Epoch [4/10], Step [100/150], Loss: 1.5687\n",
    "Epoch [4/10], Step [150/150], Loss: 1.5136\n",
    "Epoch [5/10], Step [50/150], Loss: 1.5525\n",
    "Epoch [5/10], Step [100/150], Loss: 1.4323\n",
    "Epoch [5/10], Step [150/150], Loss: 1.3860\n",
    "Epoch [6/10], Step [50/150], Loss: 1.4303\n",
    "Epoch [6/10], Step [100/150], Loss: 1.3143\n",
    "Epoch [6/10], Step [150/150], Loss: 1.2771\n",
    "Epoch [7/10], Step [50/150], Loss: 1.3240\n",
    "Epoch [7/10], Step [100/150], Loss: 1.2118\n",
    "Epoch [7/10], Step [150/150], Loss: 1.1835\n",
    "Epoch [8/10], Step [50/150], Loss: 1.2314\n",
    "Epoch [8/10], Step [100/150], Loss: 1.1234\n",
    "Epoch [8/10], Step [150/150], Loss: 1.1032\n",
    "Epoch [9/10], Step [50/150], Loss: 1.1503\n",
    "Epoch [9/10], Step [100/150], Loss: 1.0464\n",
    "Epoch [9/10], Step [150/150], Loss: 1.0338\n",
    "Epoch [10/10], Step [50/150], Loss: 1.0792\n",
    "Epoch [10/10], Step [100/150], Loss: 0.9793\n",
    "Epoch [10/10], Step [150/150], Loss: 0.9734\n",
    "Training complete in: 0:00:26.337336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Apex for mixed precision\n",
    "* mnist apex: https://github.com/yangkky/distributed_tutorial/blob/master/src/mnist-mixed.py\n",
    "* apex examples: https://github.com/nvidia/apex/tree/master/examples\n",
    "* apex tutorial: https://devblogs.nvidia.com/apex-pytorch-easy-mixed-precision-training/\n",
    "* apex tutorial: https://developer.nvidia.com/automatic-mixed-precision\n",
    "* apex doc: https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html\n",
    "\n",
    "Mixed precision training: majority of the network uses FP16 arithmetic, while automatically casting potentially unstable operations to FP32.\n",
    "\n",
    "Advantages:\n",
    "* reducing memory storage/bandwidth demands\n",
    "* use larger batch sizes\n",
    "* take advantage of NVIDIA Tensor Cores for gemms and convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gpu, world_size, nr, gpus):\n",
    "\n",
    "    rank = nr * gpus + gpu  # global rank of the process                       \n",
    "    dist.init_process_group(backend='nccl', \n",
    "                            init_method='env://',                                   \n",
    "                            world_size=world_size,                              \n",
    "                            rank=rank)                                                          \n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "    model = ConvNet()\n",
    "    torch.cuda.set_device(gpu)\n",
    "    model.cuda(gpu)\n",
    "    batch_size = 100\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n",
    "    \n",
    "    ###############################################################\n",
    "    # Wrap the model\n",
    "    model, optimizer = amp.initialize(model, optimizer, \n",
    "                                      opt_level='O2')\n",
    "    model = DDP(model)\n",
    "    ###############################################################\n",
    "\n",
    "    # Data loading code\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "        download=True\n",
    "    )                                               \n",
    "\n",
    "    # makes sure that each process gets a different slice of the training data\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset,\n",
    "                                                                    num_replicas=world_size,\n",
    "                                                                    rank=rank)\n",
    "    # Use the nn.utils.data.DistributedSampler instead of shuffling the usual way\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0,\n",
    "                                               pin_memory=True,\n",
    "                                               sampler=train_sampler)\n",
    "\n",
    "    start = datetime.now()\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            labels = labels.cuda(non_blocking=True)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            ##############################################################\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            ##############################################################\n",
    "        \n",
    "            optimizer.step()\n",
    "            if (i + 1) % 100 == 0 and gpu == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                    epoch + 1, \n",
    "                    epochs, \n",
    "                    i + 1, \n",
    "                    total_step,\n",
    "                    loss.item())\n",
    "                   )\n",
    "    if gpu == 0:\n",
    "        print(\"Training complete in: \" + str(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horovod\n",
    "\n",
    "https://docs.databricks.com/applications/deep-learning/distributed-training/mnist-pytorch.html\n",
    "\n",
    "https://horovod.readthedocs.io/en/latest/pytorch.html\n",
    "\n",
    "https://github.com/horovod/horovod/blob/master/docs/pytorch.rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
